{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open using Databricks Platform/Py-spark. It holds the code for developing the RandomForest Classifier on the chosen subset of important features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import pyspark\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
    "import gc\n",
    "from pyspark.sql.functions import col, count, sum\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "REPLACE_YOUR_FILE = \"/FileStore/tables/e9svdv4y1482386357547/test_numeric.csv\"\n",
    "df0 = sqlContext.read.format(\"csv\").load(REPLACE_YOUR_FILE, header=\"true\", inferSchema=\"true\")\n",
    " \n",
    "\n",
    "df = df0.na.fill(99999)\n",
    "df = df.na.drop()\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature=['L3_S31_F3846','L1_S24_F1578','L3_S33_F3857','L1_S24_F1406','L3_S29_F3348','L3_S33_F3863',\n",
    "            'L3_S29_F3427','L3_S37_F3950','L0_S9_F170', 'L3_S29_F3321','L1_S24_F1346','L3_S32_F3850',\n",
    "            'L3_S30_F3514','L1_S24_F1366','L2_S26_F3036']\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature,\n",
    "    outputCol='features')\n",
    "data = (assembler.transform(df).select(\"features\", df.Response.astype('double')))\n",
    "\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed=451)\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = RandomForestClassifier(numTrees=60, seed=1111, maxDepth=15, labelCol=\"Response\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[cls])\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Response\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "trainingData=trainingData.na.drop()\n",
    "trainingData.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# making predictions\n",
    "predicted = model.transform(testData)\n",
    "response = predictions.select(\"Response\").rdd.map(lambda r: r[0]).collect()\n",
    "predictedValue = predictions.select(\"probability\").rdd.map(lambda r: int(r[0][1])).collect()\n",
    "\n",
    "mcc = matthews_corrcoef(response, predictedValue)\n",
    "print (mcc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": "bda",
  "notebookId": 823926225929880
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
